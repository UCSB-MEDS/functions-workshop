---
title: "An iterative approach to streamlining your analytical workflows using functions and for loops"
author: Sam Csik
date: April 14, 2023
format: 
  html:
    theme: minty
    toc: true
    toc-location: left
    code-annotations: hover
editor_options: 
  chunk_output_type: console
---

By now, you may have heard instructors or online resources quote the saying, "If you've copied a block of code more than twice, you should probably consider writing a function." 

As your analyses get longer and more complex, the chances that you'll benefit from writing functions will also increase -- many times, this is to minimize the amount of code you need to copy/paste, but writing functions can also help to make your code:

-  more navigable (e.g. by partitioning your code and functions into separate files)
-  more readable (e.g. creating human-readable function names that tell a user exactly what to expect)
-  less prone to errors (e.g. less copying/pasting large code chunks means less opportunity to introduce bugs)

Iteration (i.e. performing the same operation on multiple inputs, e.g. multiple data sets, columns, etc.) is another tool for reducing duplication -- for loops are one approach for performing iterative tasks. Together, both functions and for loops provide a powerful means to streamlining your analytical pipelines.

*However*, whether you're a new learner or seasoned programmer, it can sometimes feel overwhelming to know exactly where to start -- especially when you have an end goal that builds additional complexity/flexibility into your functions and for loops. Taking an iterative approach to building out your code can help make this process clearer, less daunting, and more fun. 

This document walks through *my* own iterative process for writing a couple functions and for loops to clean and visualize multiple, similar data sets. The way I've written this code is certainly not the *only* way (and likely not even the most optimized way), but I hope that by stepping through how I slowly build out my functions to be more flexible and user-friendly, it might help demonstrate an iterative workflow that I find particularly effective.

## `r fontawesome::fa("file-lines", fill = "#5A5A5A", a11y = "sem")` How is this document organized?

::: {.callout-important}
## This workshop is indended to be taught in-person
I'll be doing a lot of writing code, then testing code, then adding a bit more code, rinsing, and repeating. That can be a bit hard to capture in an instructional document, but I've done my best to outline my iterative steps here for folks to refer back to, as-needed.
:::

This document follows just one case study -- creating functions and for loops for processing and visualizing ocean temperature data from a few Santa Barbara Coastal LTER rocky reef sites. I do this in three "Stages", each of which includes multiple steps/code versions:

**`r fontawesome::fa("person-walking", fill = "#5A5A5A", a11y = "sem")` Stage 1:** Clean and plot *one* data set -- *always* my first step when beginning any analysis

-  this is a standard workflow that includes reading in the data, then cleaning and plotting at least one data set (I include these steps for all three data sets, for reference...this involves lots of copying and pasting large chunks of code!)

**`r fontawesome::fa("person-running", fill = "#5A5A5A", a11y = "sem")` Stage 2:** Write functions to clean & plot your data -- getting a little fancier by turning long, repeated code chunks into functions   

-  Here I create two separate functions, one to clean data and one to plot data -- for each, I take a super iterative approach (i.e. I start by creating a relatively simple function (that works!), then build in more flexibility/complexity)

**`r fontawesome::fa("rocket", fill = "#5A5A5A", a11y = "sem")` Stage 3:** Write for loops to read in, clean, and plot all your data -- streamline processing all of our data sets using less code

-  Once I've created functions that help to reduce the code needed for processing and plotting my data, I write a few for loops to read in, clean, and plot all files (while this may seem a bit silly for just three files, imagine having to process/plot dozens or more!). Again, I do this in a few separate steps so I can ensure each small piece works before adding in the next bit.
  
ADD TEXT ABOUT SYMBOL FOR LOOKING STUFF UP   
ADD TEXT ABOUT ANNOTATIONS

## `r fontawesome::fa("table", fill = "#5A5A5A", a11y = "sem")` About the Data

The Santa Barbara Coastal Long Term Ecological Research (SBC LTER) site was established in 2000 and is located in Santa Barbara's coastal zone, where ocean currents and climate are highly variable with season and longer-term cycles. A number of kelp forest/rocky reef sites exist, where long-term data collection occurs using a variety of methods, including both repeated surveys and moored instrumentation. Today, we'll be exploring ocean temperature data, collected via moored instrumentation ([CTD](https://en.wikipedia.org/wiki/CTD_(instrument)#:~:text=A%20CTD%20or%20sonde%20is,is%20used%20to%20determine%20salinity.)s), from just three of these sites: Alegria Reef, Mohwak Reef, and Carpinteria Reef.

Raw data are available for download on the [EDI Data Portal](https://portal.edirepository.org/nis/home.jsp):

  1. Alegria Reef: <https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-sbc.2008.14>
  2. Mohawk Reef: <https://doi.org/10.6073/pasta/cbe43646b801bf6ee5231c301ea23f51>
  3. Carpinteria Reef: <https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-sbc.2004.26>

## `r fontawesome::fa("folder-tree", fill = "#5A5A5A", a11y = "sem")` Setup

1. create and clone a GitHub repository (be sure to add a `.gitignore` file)
2. download the data -- these data are publicly available via the [EDI Data Portal](https://portal.edirepository.org/nis/home.jsp), but I've also added the necessary files to Google Drive for download [here](https://drive.google.com/drive/folders/1S2IY-qo29CU9ahRj_QNfFLfrh7DnT3CG?usp=share_link) -- these are *large* data files and take a few minutes to download; be sure to unzip the files once downloaded
3. add a subdirectory called `/data`; move your unzipped `raw_data` folder into the `/data` subdirectory; your folder structure should now look like: `your-repo/data/raw_data`
4. add your `/raw_data` folder to your `.gitignore` file so that you don't accidentally try pushing it to GitHub (these data files are far too large for that!) -- to do so, scroll to the bottom of your `.gitignore`, type the following, `data/raw_data/`, and save; you can push this modified `.gitignore` file to GitHub now, if you'd like

## **`r fontawesome::fa("person-walking", fill = "#5A5A5A", a11y = "sem")` Stage 1:** Clean and plot *one* data set 

Copying, pasting, and slightly updating code to clean and process multiple similarly-structured data sets is certainly the slowest and most prone-to-errors workflow. However, (in *my* honest opinion) it's almost always critical to being by processing one data set on it's own before attempting to write a function to do so.

Let's start by doing that here.

::: {.callout-note}
I'll be writing the following code in a script called, `no_functions_pipeline.R`, which I'll save to my repo's root directory.
:::

### **i.** Load libraries
```{r}
#| eval: true
#| echo: true
#| message: false
#| warning: false
library(tidyverse)
library(chron)
library(naniar)
library(ggridges)
```

### **ii.** Import raw data 

Either download from the [Environmental Data Portal](https://portal.edirepository.org/nis/home.jsp) (EDI) directly: 
```{r}
#| eval: true
#| echo: true
#| message: false
#| warning: false
# ale <- read_csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.2008.14&entityid=15c25abf9bb72e2017301fa4e5b2e0d4")
# mko <- read_csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.2007.16&entityid=02629ecc08a536972dec021f662428aa")
# car <- read_csv("https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-sbc.2004.26&entityid=1d7769e33145ba4f04aa0b0a3f7d4a76")
```

Or read in the downloaded files from `data/raw_data/`
```{r}
#| eval: true
#| echo: true
#| message: false
#| warning: false
alegria <- read_csv(here::here("data", "raw_data", "alegria_mooring_ale_20210617.csv"))
mohawk <- read_csv(here::here("data", "raw_data", "mohawk_mooring_mko_20220330.csv"))
carpinteria <- read_csv(here::here("data", "raw_data", "carpinteria_mooring_car_20220330.csv"))
```

### **iii.** Clean data 

Below, we select only the necessary columns (there are *far* too many (87) in the raw data), add a column for site name (the only way to tell which site the data were collected from is by looking at the file name), formatting dates/times, and replacing missing value codes with *`NA`*.
```{r}
#| eval: true
#| echo: true
#| message: false
#| warning: false
alegria_clean <- alegria |> 
  
  # keep only necessary columns & filter for years 2005-2020
  select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
  filter(year %in% c(2005:2020)) |> 
  
  # add column with site name
  mutate(site = rep("Alegria Reef")) |> 
  
  # create date time column
  unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
  mutate(time = times(decimal_time)) |> 
  unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
  
  # coerce data types
  mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
         year = as.factor(year),
         month = as.factor(month),
         day = as.numeric(day)) |>
  
  # add month name (see: https://stackoverflow.com/questions/22058393/convert-a-numeric-month-to-a-month-abbreviation)
  mutate(month_name = as.factor(month.name[month])) |>
  
  # replace 9999s with NAs (will throw warning if var isn't present, but still execute)
  replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
  
  # select/reorder desired columns
  select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)

```

### **iv.** Plot the data

Here, we create a ridge line plot (using the `{ggridges}` package) showing aggregate bottom temperatures (2005-2020), by month, at Alegria reef.
```{r}
#| eval: true
#| echo: true
#| message: false
#| warning: false
alegria_plot <- alegria_clean |> 
  
  # group by month ----
  group_by(month_name) |> 
  
  # plot ----
  ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
  geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
  scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
  scale_y_discrete(limits = rev(month.name)) + 
  scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
  labs(x = "Bottom Temperature (°C)",
       title = "Bottom Temperatures at Alegria Reef, Santa Barbara, CA",
       subtitle = "Temperatures (°C) aggregated by month from 2005 - 2020") +
  ggridges::theme_ridges(font_size = 13, grid = TRUE) +
  theme(
    axis.title.y = element_blank()
  )

alegria_plot
```

If we were to continue with this workflow (which is absolutely a valid way that gets the job done!), we would need to repeat the above code two more times (for both the `mohawk` and `carpinteria` data frames) -- this gets lengthy rather quickly, requires lots of copying/pasting, and is prone to errors (e.g. forgetting to update a data frame name, typos, etc.). If you'd like to check out the code for the `mohawk` and `carpinteria` data sets, unfold the code chunk below:

```{r}
#| eval: true
#| echo: true
#| code-fold: true
#| layout-ncol: 2
#| message: false
#| warning: false

#..........................Mohawk Reef...........................

# clean ----
mohawk_clean <- mohawk |> 
  select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
  filter(year %in% c(2005:2020)) |> 
  mutate(site = rep("Mohawk Reef")) |> 
  unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
  mutate(time = times(decimal_time)) |> 
  unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
  mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
         year = as.factor(year),
         month = as.factor(month),
         day = as.numeric(day)) |>
  mutate(month_name = as.factor(month.name[month])) |>
  replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
  select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)

# plot ----
mohawk_plot <- mohawk_clean |> 
  group_by(month_name) |> 
  ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
  geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
  scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
  scale_y_discrete(limits = rev(month.name)) + 
  scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
  labs(x = "Bottom Temperature (°C)",
       title = "Bottom Temperatures at Mohawk Reef, Santa Barbara, CA",
       subtitle = "Temperatures (°C) aggregated by month from 2005 - 2020") +
  ggridges::theme_ridges(font_size = 13, grid = TRUE) +
  theme(
    axis.title.y = element_blank()
  )

mohawk_plot

#........................Carpinteria Reef........................

# clean ----
carpinteria_clean <- carpinteria |> 
  select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
  filter(year %in% c(2005:2020)) |> 
  mutate(site = rep("Carpinteria Reef")) |> 
  unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
  mutate(time = times(decimal_time)) |> 
  unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
  mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
         year = as.factor(year),
         month = as.factor(month),
         day = as.numeric(day)) |>
  mutate(month_name = as.factor(month.name[month])) |>
  replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
  select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)

# plot ----
carpinteria_plot <- carpinteria_clean |> 
  group_by(month_name) |> 
  ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
  geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
  scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
  scale_y_discrete(limits = rev(month.name)) + 
  scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
  labs(x = "Bottom Temperature (°C)",
       title = "Bottom Temperatures at Carpinteria Reef, Santa Barbara, CA",
       subtitle = "Temperatures (°C) aggregated by month from 2005 - 2020") +
  ggridges::theme_ridges(font_size = 13, grid = TRUE) +
  theme(
    axis.title.y = element_blank()
  )

carpinteria_plot
```

## **`r fontawesome::fa("person-running", fill = "#5A5A5A", a11y = "sem")` Stage 2:** Write functions to clean & plot your data

::: {.callout-note}
## Where do I write/save my functions?
While there's no hard and fast rule, I tend to create a subdirectory within my project (e.g. named `/R`, `/utils`, etc.) to house all my function scripts. I prefer to create a separate `.R` script for each of my functions, and name each file the same as the function itself (e.g. if I'm writing a function called `do_fun_thing()`, I'd save it to a script called `do_fun_thing.R`).

You can then **source** your function files into whatever script (or `.rmd`/`.qmd` file) where you call that function (e.g. `source("utils/do_fun_thing.R")`. 

**Note:** You *cannot* `source()` a `.rmd` or `.qmd` file into another file/script, therefore it's important to save functions to a `.R` file.

Here, let's create the following:

-  a `/utils` folder to store our functions scripts
-  a `clean_ocean_temps.R` file (saved to `/utils`), where we'll write a function to clean our data
-  a `plot_ocean_temps.R` file (saved to `/utils`), where we'll write a function to plot our data
-  a `using_functions_pipeline.R` file (saved to the root directory), where we'll use our functions to clean and plot our data -- you can also read-in your data files here, just as we did in [Stage 1, part ii](http://localhost:7074/#ii.-import-raw-data)
:::

### **i.** Write a function to **clean** data sets

It's helpful to first identify which parts of the cleaning code need to be generalized/made "flexible" so that any of our three data frames can be passed to it for cleaning. For us, that's:

1.  the name of the raw data frame
2.  the site name character string that's repeated for the length of the added `site` column

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_clean <- alegria |> # <1>
  select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
  filter(year %in% c(2005:2020)) |> 
  mutate(site = rep("Alegria Reef")) |> # <2>
  unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
  mutate(time = times(decimal_time)) |> 
  unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
  mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
         year = as.factor(year),
         month = as.factor(month),
         day = as.numeric(day)) |>
  mutate(month_name = as.factor(month.name[month])) |>
  replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
  select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
```
1. the name of the raw data frame (here, `alegria`) needs to be generalized
2. the site name character string that's repeated for the length of the added `site` column (here, **"Alegria Reef"**) needs to be generalized

Now we can start to build out our function. We'll start by creating a super basic function, then build in more complexity. I encourage you to test out your function after each version to ensure that it works as you intend it to.

::: {.callout-important}
## Reminder
We'll be writing our `clean_temp_data()` function in our `/utils/clean_temp_data.R` file!
:::

::: panel-tabset

## Version 1 

To start, let's create the skeleton of our function, which we'll call `clean_ocean_temps()`:
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
clean_ocean_temps <- function(){
  
}
```

Now, let's copy and paste our cleaning code for Alegria Reef data (from **Stage 1**, above) into the body of the function (i.e. within the curly brackets, `{}`).
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
clean_ocean_temps <- function(){
 
  alegria_clean <- alegria |> 
    select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
    filter(year %in% c(2005:2020)) |> 
    mutate(site = rep("Alegria Reef")) |> 
    unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
    mutate(time = times(decimal_time)) |> 
    unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
    mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
          year = as.factor(year),
          month = as.factor(month),
          day = as.numeric(day)) |>
    mutate(month_name = as.factor(month.name[month])) |>
    replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
    select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
  
}
```

Next, we want the ability to provide our function with any three of our data sets for processing. We'll do this following these steps: 

1.  create an input (aka **argument**) called `raw_data` inside `function()` (NOTE: you can name your argument however you'd like, but preferably something short and descriptive) 
2.  replace our hard-coded data frame name (e.g. `alegria` in the code above) in our cleaning pipeline with `raw_data`
3.  update the name of the object we save our clean data to (currently `alegria_clean`) to something a bit more generalized, like `temps_clean` and `return()` our clean data frame object at the end
4.  recall that part of our cleaning pipeline includes adding a column called `site`, with repeating values that are the site name; for now, let's just add some placeholder text (*___ Reef*) and we'll figure out how to make that text match up with the data in the next versions of our function

::: {.callout-note collapse="true"}
## What is `return()` and when is it necessary?

Oftentimes, we want a function to do some processing on whatever we provide it and then give us back the result. We use the `return()` function to do this in R. 

R **automatically** returns the the last output of a function -- here, it isn't necessary to `return(temps_clean)` since the `temps_clean` data frame is the last output of our `clean_ocean_temps()` function.  

An explicit `return()` is used to return a value immediately from a function. If it is *not* the last statement of a function, `return()` will prematurely end the function -- for example, if `x = 2`, the string, `"Positive"` will be returned (and the remaining `if else` statement will not be executed):

```{r}
check_number <- function(x) {
  if (x > 0) {
    return("Positive")
  }
  else if (x < 0) {
    return("Negative")
  }
  else {
    return("Zero")
  }
}
```

I tend to include an explicit `return()` at the end of my functions because I think it makes it easier to read/understand the code, but check out [this interesting dialogue](https://stackoverflow.com/questions/11738823/explicitly-calling-return-in-a-function-or-not) on whether this is best practice or not.

:::

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
clean_ocean_temps <- function(raw_data){ # <1>
  
  # clean data ----
  temps_clean <- raw_data |> # <2>
    select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
    filter(year %in% c(2005:2020)) |> 
    mutate(site = rep("___ Reef")) |> # <4>
    unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
    mutate(time = times(decimal_time)) |> 
    unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
    mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
          year = as.factor(year),
          month = as.factor(month),
          day = as.numeric(day)) |>
    mutate(month_name = as.factor(month.name[month])) |>
    replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
    select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
  
  # return cleaned df ----
  return(temps_clean) # <3>
}
```
1. create an  **argument** called `raw_data` inside `function()` 
2. replace our hard-coded data frame name (e.g. `alegria`) with our new argument name, `raw_data`
3. update the name of the object we save our clean data to (currently `alegria_clean`) to something a bit more generalized, like `temps_clean` and `return()` our clean data frame object at the end
4. add placeholder text in for `site` (we'll work on making this flexible in Version )

Lastly, let's make sure our function works. Run your function so that it's saved to your global environment, then use it on your raw data sets:
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_clean <- clean_ocean_temps(raw_data = alegria)
mohawk_clean <- clean_ocean_temps(raw_data = mohawk)
carpinteria_clean <- clean_ocean_temps(raw_data = carpinteria)
```

## Version 2

Before we get too far, it's probably a good idea to make sure any required dependencies are loaded with our function. A good way to check that your function works as-is is to restart R, reload your data and your function, then use your function:

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
#......load in data using only the required packages (readr).....
alegria <- readr::read_csv(here::here("data", "raw_data", "alegria_mooring_ale_20210617.csv"))
mohawk <- readr::read_csv(here::here("data", "raw_data", "mohawk_mooring_mko_20220330.csv"))
carpinteria <- readr::read_csv(here::here("data", "raw_data", "carpinteria_mooring_car_20220330.csv"))

#......................re-load your function.....................
clean_ocean_temps <- function(raw_data){ 
  
  # clean data ----
  temps_clean <- raw_data |>
    select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
    filter(year %in% c(2005:2020)) |> 
    mutate(site = rep("___ Reef")) |>
    unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
    mutate(time = times(decimal_time)) |> 
    unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
    mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
          year = as.factor(year),
          month = as.factor(month),
          day = as.numeric(day)) |>
    mutate(month_name = as.factor(month.name[month])) |>
    replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
    select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
  
  # return cleaned df ----
  return(temps_clean) 
}

#....................try using your function.....................
alegria_clean <- clean_ocean_temps(raw_data = alegria)
mohawk_clean <- clean_ocean_temps(raw_data = mohawk)
carpinteria_clean <- clean_ocean_temps(raw_data = carpinteria)
```

**Does it work?**

If you're following along here, you most likely got an error message that says something like `...could not find function "select"`. We use lots of existing functions within `clean_ocean_temps()` that are called from external packages: `{dplyr}`, `{tidyr}`, `{chron}`, `{naniar}`. It's best not to assume that a user (including yourself) will have already installed and loaded those packages prior to trying to use `clean_ocean_temps()`. To fix this, we can: 

1. call `library()` inside our function to load all required packages before executing our cleaning code. If a user tries to use `clean_ocean_names()` but doesn't have a required package(s) already installed, it will return an error (e.g. `Error in library(x): there is no package called 'x'`).

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
clean_ocean_temps <- function(raw_data){ 
  
  # load dependencies ---- # <1>
  library(dplyr) 
  library(tidyr)
  library(chron)
  library(naniar)
  
  # clean data ----
  temps_clean <- raw_data |>
    select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
    filter(year %in% c(2005:2020)) |> 
    mutate(site = rep("___ Reef")) |>
    unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
    mutate(time = times(decimal_time)) |> 
    unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
    mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
          year = as.factor(year),
          month = as.factor(month),
          day = as.numeric(day)) |>
    mutate(month_name = as.factor(month.name[month])) |>
    replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
    select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
  
  # return cleaned df ----
  return(temps_clean) 
}
```
1. load any dependencies (i.e. packages that are used within your function)

Again, rerun your updated function and try using it to make sure it works as intended:
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_clean <- clean_ocean_temps(raw_data = alegria)
mohawk_clean <- clean_ocean_temps(raw_data = mohawk)
carpinteria_clean <- clean_ocean_temps(raw_data = carpinteria)
```

## Version 3

Next, let's work on adding the appropriate site name to our `site` column. There are *many* creative ways to go about forming the site name that will get added as a repeating value to the `site` column -- two that came to mind to start were:

a. adding a second function argument that takes a site name as a character string (e.g. `site_name = "Alegria Reef"`) 
b. getting the site name from the raw data object name (e.g. the data `alegria_mooring_ale_20210617.csv` was saved to an object named `alegria`)

Here, we'll opt for option (b). To do so, we need to: 

1. use the `deparse()` and `substitute()` functions together to convert an object name (here, `raw_data`) to a character string (`r fontawesome::fa("book-open-reader", fill = "#5A5A5A", a11y = "sem")` this [resource](https://statisticsglobe.com/convert-name-of-data-object-to-character-string-in-r ) was helpful for figuring this out)
2.  format our extracted character string (convert to Title Case and paste `"Reef"` at the end)
3.  substitute our formatted character string site name in for the hard-coded site name in `mutate(site = rep("___ Reef"))`
4.  don't forget to import the `{stringr}` package at the top of your function!
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
clean_ocean_temps <- function(raw_data){
  
  # load dependencies ----
  library(dplyr) 
  library(tidyr)
  library(stringr) # <1>
  library(chron)
  library(naniar)
 
  # get site name as character string from object (raw_data) name ----
  site_name <- deparse(substitute(raw_data)) # <2>
  site_name <- paste(str_to_title(site_name), "Reef") # <3>
    
  # clean data ----
  temps_clean <- raw_data |> 
    select(year, month, day, decimal_time, Temp_top, Temp_mid, Temp_bot) |>
    filter(year %in% c(2005:2020)) |> 
    mutate(site = rep(site_name)) |> # <4>
    unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
    mutate(time = times(decimal_time)) |> 
    unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
    mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
          year = as.factor(year),
          month = as.factor(month),
          day = as.numeric(day)) |>
    mutate(month_name = as.factor(month.name[month])) |>
    replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
    select(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top)
  
  # return cleaned df ----
  return(temps_clean) 
}
```
1. import `{stringr}` package
2. get a character string from the data frame name (e.g. for `clean_ocean_temps(raw_df = alegria)`, `site_name` will be set to `"alegria"`)
3. format the character string by converting it to Title Case and pasting `"Reef"` at the end (e.g. `"alegria"` will become `"Alegria Reef"`)
4. substitute `site_name` in for the hard-coded site name

Rerun the updated function and try using it to make sure the appropriate site name is added to the `site_name` column for each of the data sets:
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_clean <- clean_ocean_temps(raw_data = alegria)
mohawk_clean <- clean_ocean_temps(raw_data = mohawk)
carpinteria_clean <- clean_ocean_temps(raw_data = carpinteria)
```

## Version 4

Our function works perfectly fine as is, but let's say we don't always want all three temperature measurements (surface temperature (`Temp_top`), mid-column temperature (`Temp_mid`), and bottom temperature (`Temp_top`)) included in our cleaned data. We can build flexibility into our function by adding an argument that allows the user to select exactly which of the three temperature measurements to include in the resulting cleaned data frame. To do this, we'll:

1.  add an argument called `include_temps`, which defaults to including all three temperature variables
2.  create a vector of variables to `select` in our cleaning pipeline; recall that the raw data frame includes 87 variables -- our cleaning pipeline starts by selecting just the few we care about, but that `select` call must now be made flexible enough to accept some or all temperature variables based on user inputs (this [resource](https://tidyselect.r-lib.org/reference/all_of.html) was helpful for figuring this out)
3.  make our last `select` call, which is used to reorder columns, flexible enough to reorder temperature variables which may or may not be present (this [resource](https://tidyselect.r-lib.org/reference/all_of.html) was again helpful for figuring this out)
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
clean_ocean_temps <- function(raw_data, include_temps = c("Temp_top", "Temp_mid", "Temp_bot")){ # 1
  
  # load dependencies ----
  library(dplyr) 
  library(tidyr)
  library(stringr)
  library(chron)
  library(naniar)
  
  # get site name as character string from object (raw_data) name ----
  site_name <- deparse(substitute(raw_data)) 
  site_name <- paste(str_to_title(site_name), "Reef") 
  
  # columns to select ---- 
  always_selected_cols <- c("year", "month", "day", "decimal_time") 
  all_cols <- append(always_selected_cols, include_temps) # 2
  
  # clean data ----
  temps_clean <- raw_data |> 
    select(all_of(all_cols)) |> # 2
    filter(year %in% c(2005:2020)) |> 
    mutate(site = rep(site_name)) |> 
    unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
    mutate(time = times(decimal_time)) |> 
    unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
    mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
           year = as.factor(year),
           month = as.factor(month),
           day = as.numeric(day)) |>
    mutate(month_name = as.factor(month.name[month])) |>
    replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
    select(any_of(c(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top))) # 3
  
  # return cleaned df ----
  return(temps_clean) 
}
```
<!-- 1. add a second argument called `include_temps` with default values `Temp_top`, `Temp_mid`, and `Temp_bot` -->
<!-- 2. create a vector of variables to `select` from the raw data, based on user-specified temperature variables in `include_temps` -->
<!-- 3. make this `select` flexible enough to reorder temperature variables which may or may not be present, depending on what the user specifies in the `include_temps` argument -->

Rerun the updated function and try out our new `inlcude_temps` argument: 
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_clean <- clean_ocean_temps(raw_data = alegria, include_temps = c("Temp_bot")) # includes only `Temp_bot`
mohawk_clean <- clean_ocean_temps(raw_data = mohawk) # includes all three temp cols (`Temp_top`, `Temp_mid`, `Temp_bot`) by default
carpinteria_clean <- clean_ocean_temps(raw_data = carpinteria, include_temps = c("Temp_mid", "Temp_bot")) # includes only `Temp_mid` & `Temp_bot`
```

**Note:** `naniar::replace_with_na()` will throw a warning message (but does *not* halt execution) if one or more of the temperature variables are missing (e.g. if we specify `include_temps = c("Temp_bot")`, you will get a warning that says, `Missing from data: Temp_top, Temp_mid`).

## Version 5

To wrap things up, we might consider adding an `if else` statement that checks to ensure that the data provided is suitable for our cleaning pipeline. Here, we'll: 

1.  add an `if else` statement that checks whether the necessary columns are present in the raw data -- if yes, proceed with data cleaning; if no, throw an error message
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
clean_ocean_temps <- function(raw_data, include_temps = c("Temp_top", "Temp_mid", "Temp_bot")){ 
  
  # load dependencies ----
  library(dplyr) 
  library(tidyr)
  library(stringr) 
  library(chron)
  library(naniar)
  
  # if data contains these colnames, clean the script
  if(all(c("year", "month", "day", "decimal_time", "Temp_bot", "Temp_top", "Temp_mid") %in% colnames(raw_data))) { 
    
    message("Cleaning data...") 
    
    # get site name as character string from object (raw_data) name ----
    site_name <- deparse(substitute(raw_data)) 
    site_name <- paste(str_to_title(site_name), "Reef") 
    
    # columns to select ----
    standard_cols <- c("year", "month", "day", "decimal_time") 
    all_cols <- append(standard_cols, include_temps) 
    
    # clean data ----
    temps_clean <- raw_data |> 
      select(all_of(all_cols)) |> 
      filter(year %in% c(2005:2020)) |> 
      mutate(site = rep(site_name)) |> 
      unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
      mutate(time = times(decimal_time)) |> 
      unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
      mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
             year = as.factor(year),
             month = as.factor(month),
             day = as.numeric(day)) |>
      mutate(month_name = as.factor(month.name[month])) |>
      replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
      select(any_of(c(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top))) 
    
    # return cleaned df ----
    return(temps_clean) 
    
  } else { 
    
    stop("The data frame provided does not include the necessary columns. Double check your data!") 
    
  }
  
}
```

Let's rerun our function and try it out one last time: 
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
# these three should work as intended
alegria_clean <- clean_ocean_temps(raw_data = alegria, include_temps = c("Temp_bot")) 
mohawk_clean <- clean_ocean_temps(raw_data = mohawk) 
carpinteria_clean <- clean_ocean_temps(raw_data = carpinteria, include_temps = c("Temp_mid", "Temp_bot")) 

# this should throw an error!
penguins_clean <- clean_ocean_temps(raw_data = palmerpenguins::penguins) 
```

:::

### **ii:** Write a function to **plot** data sets

Similar to what we did for our cleaning code, let's first identify which parts of the plotting code need to be generalized/made "flexible" so that any of our three cleaned data frames can be passed to it for plotting. For us, that's:

1.  the name of the clean data frame
2.  the site name that appears in the plot title

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_plot <- alegria_clean |> 
  group_by(month_name) |> 
  ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
  geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
  scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
  scale_y_discrete(limits = rev(month.name)) + 
  scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
  labs(x = "Bottom Temperature (°C)",
       title = "Bottom Temperatures at Alegria Reef, Santa Barbara, CA",
       subtitle = "Temperatures (°C) aggregated by month from 2005 - 2020") +
  ggridges::theme_ridges(font_size = 13, grid = TRUE) +
  theme(
    axis.title.y = element_blank()
  )

alegria_plot
```

::: panel-tabset

## Version 1

Now we can begin to building our function. Let's again start by creating the skeleton of our function, which we’ll call `plot_ocean_temps()`:
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
plot_ocean_temps <- function(){
  
}
```

...then copy and paste our plotting code for the clean Alegria Reef data into the body of the function (i.e. within the curly brackets, `{}`).
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
plot_ocean_temps <- function() {

  alegria_plot <- alegria_clean |> 
    group_by(month_name) |> 
    ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
    geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
    scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
    scale_y_discrete(limits = rev(month.name)) + 
    scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
    labs(x = "Bottom Temperature (°C)",
         title = "Bottom Temperatures at Alegria Reef, Santa Barbara, CA",
         subtitle = "Temperatures (°C) aggregated by month from 2005 - 2020") +
    ggridges::theme_ridges(font_size = 13, grid = TRUE) +
    theme(
      axis.title.y = element_blank()
    )
  
}
```

Just like in `clean_ocean_temps()`, we want the ability to provide our function with any three of our cleaned data sets for plotting. We’ll do this following these steps:

1.  create an input (aka argument) called `clean_data` inside `function()` (NOTE: you can name your argument however you’d like, but preferably something short and descriptive)
2.  replace our hard-coded data frame name (e.g. `alegria_clean` in the code above) in our plotting pipeline with `clean_data`
3.  update the name of the object we save our plot output to (currently `alegria_plot`) to something a bit more generalized, like `temps_plot` and `return()` our plot object at the end
4. don't forget to load any dependencies within the function!
5. and add some placeholder text (*___ Reef*) in the `title` field -- we'll make this flexible in our next version
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
plot_ocean_temps <- function(clean_data) { # step 1
  
  # load dependencies ----
  library(dplyr)
  library(ggplot2)
  library(ggridges)

  # plot data ----
  temps_plot <- clean_data |> # steps 2 & 3.1
    group_by(month_name) |> 
    ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
    geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
    scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
    scale_y_discrete(limits = rev(month.name)) + 
    scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
    labs(x = "Bottom Temperature (°C)",
         title = "Bottom Temperatures at ___ Reef, Santa Barbara, CA",
         subtitle = "Temperatures (°C) aggregated by month from 2005 - 2020") +
    ggridges::theme_ridges(font_size = 13, grid = TRUE) +
    theme(
      axis.title.y = element_blank()
    )
  
  # return plot ----
  return(temps_plot) # steps 3.2
  
}
```

Now let's make sure our function works. Run the function so that it's saved to our global environment, then use it to try plotting our cleaned data sets:
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_plot <- plot_ocean_temps(clean_data = alegria_clean) 
mohawk_plot <- plot_ocean_temps(clean_data = mohawk_clean)
carpinteria_plot <- plot_ocean_temps(clean_data = carpinteria_clean) 
```

## Version 2

In this next version, let's figure out how to update the `title` so that the appropriate site name appears each time a different data set is plotted. Luckily for us, we've already added a `site` column to our `*_clean` data. Because each cleaned data frame only contains data from a single site, we can:

1. use the `unique()` function to get the site name for a given data set
2. use the `paste()` function to construct a `title` using our extracted site name
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
plot_ocean_temps <- function(clean_data) { 
  
  # load dependencies ----
  library(dplyr)
  library(ggplot2)
  library(ggridges)
  
  # get site name for plot title ----
  site_name <- unique(clean_data$site) # 1
  
  # plot data ----
  temp_plot <- clean_data |> 
    group_by(month_name) |> 
    ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
    ggridges::geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
    scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
    scale_y_discrete(limits = rev(month.name)) + 
    scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
    labs(x = "Bottom Temperature (°C)",
         title = paste("Bottom Temperatures at",  site_name, ", Santa Barbara, CA"), # 2
         subtitle = "Temperatures (°C) aggregated by month from 2005 - 2022") +
    ggridges::theme_ridges(font_size = 13, grid = TRUE) +
    theme(
      axis.title.y = element_blank()
    )
  
  # return plot ----
  return(temp_plot)
}
```

Rerun and try out your function again to make sure it works as expected:
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
alegria_plot <- plot_ocean_temps(clean_data = alegria_clean) 
mohawk_plot <- plot_ocean_temps(clean_data = mohawk_clean)
carpinteria_plot <- plot_ocean_temps(clean_data = carpinteria_clean) 
```
:::

### **iii:** Putting it all together

Okay, now let's bring all these pieces together! Our revised scripts might look something like this:

::: panel-tabset
## `using_functions_pipeline.R`
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
#..........................load packages.........................
library(readr)

#........................source functions........................
source("R/clean_ocean_temps.R")
source("R/plot_ocean_temps.R")

#..........................import data...........................
alegria <- read_csv(here::here("data", "raw_data", "alegria_mooring_ale_20210617.csv"))
mohawk <- read_csv(here::here("data", "raw_data", "mohawk_mooring_mko_20220330.csv"))
carpinteria <- read_csv(here::here("data", "raw_data", "carpinteria_mooring_car_20220330.csv"))

#...........................clean data...........................
alegria_clean <- clean_ocean_temps(raw_data = alegria, include_temps = c("Temp_bot")) 
mohawk_clean <- clean_ocean_temps(raw_data = mohawk, include_temps = c("Temp_bot")) 
carpinteria_clean <- clean_ocean_temps(raw_data = carpinteria, include_temps = c("Temp_bot")) 

#............................plot data...........................
alegria_plot <- plot_ocean_temps(clean_data = alegria_clean) 
mohawk_plot <- plot_ocean_temps(clean_data = mohawk_clean)
carpinteria_plot <- plot_ocean_temps(clean_data = carpinteria_clean) 
```

## `utils/clean_ocean_temps.R`
::: {.callout-note}
## Use a roxygen skeleton to document your function
Even if you don't plan to publish your function as part of a package, documenting your work is still a critical part of reproducibility and usability. This may be done in more informal ways, such as code annotations and text explanations in RMarkdown documents, for example. You may also consider more formal documentation -- the [`{roxygen2}`](https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html) package helps to make that process easier. Click anywhere inside your function, then choose Code > Insert Roxygen Skeleton to get started. 
:::

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
#' Process CDT/ADCP temperature data
#'
#' @param raw_data data frame of CTD/ADCP data collected at SBC LTER site moorings; search for data on the EDI Data Portal (http://portal.edirepository.org:80/nis/simpleSearch?defType=edismax&q=SBC+LTER%5C%3A+Ocean%5C%3A+Currents+and+Biogeochemistry%5C%3A+Moored+CTD+and+ADCP+data&fq=-scope:ecotrends&fq=-scope:lter-landsat*&fl=id,packageid,title,author,organization,pubdate,coordinates&debug=false)
#' @param include_temps vector of character strings that includes one or more of the following variable names: Temp_top, Temp_mid, Temp_top
#'
#' @return a data frame
#' @export
#'
#' @examples
#' my_clean_df <- clean_ocean_temps(raw_data = my_raw_df, include_temps = c("Temp_bot"))
clean_ocean_temps <- function(raw_data, include_temps = c("Temp_top", "Temp_mid", "Temp_bot")){ 
  
  # load dependencies ----
  library(dplyr) 
  library(tidyr)
  library(stringr) 
  library(chron)
  library(naniar)
  
  # if data contains these colnames, clean the script
  if(all(c("year", "month", "day", "decimal_time", "Temp_bot", "Temp_top", "Temp_mid") %in% colnames(raw_data))) { 
    
    message("Cleaning data...") 
    
    # get site name as character string from object (raw_data) name ----
    site_name <- deparse(substitute(raw_data)) 
    site_name <- paste(str_to_title(site_name), "Reef") 
    
    # columns to select ----
    standard_cols <- c("year", "month", "day", "decimal_time") 
    all_cols <- append(standard_cols, include_temps) 
    
    # clean data ----
    temps_clean <- raw_data |> 
      select(all_of(all_cols)) |> 
      filter(year %in% c(2005:2020)) |> 
      mutate(site = rep(site_name)) |> 
      unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
      mutate(time = times(decimal_time)) |> 
      unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
      mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
             year = as.factor(year),
             month = as.factor(month),
             day = as.numeric(day)) |>
      mutate(month_name = as.factor(month.name[month])) |>
      replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
      select(any_of(c(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top))) 
    
    # return cleaned df ----
    return(temps_clean) 
    
  } else { 
    
    stop("The data frame provided does not include the necessary columns. Double check your data!") 
    
  }
  
}
```

## `utils/plot_ocean_temps.R`

::: {.callout-note}
## Use a roxygen skeleton to document your function
Even if you don't plan to publish your function as part of a package, documenting your work is still a critical part of reproducibility and usability. This may be done in more informal ways, such as code annotations and text explanations in RMarkdown documents, for example. You may also consider more formal documentation -- the [`{roxygen2}`](https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html) package helps to make that process easier. Click anywhere inside your function, then choose Code > Insert Roxygen Skeleton to get started. 
:::

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
#' Create ridge line plot of CDT/ADCP bottom temperature data
#'
#' @param clean_data a data frame that has been pre-processed using clean_ocean_temp()
#'
#' @return a plot object
#' @export
#'
#' @examples
#' my_plot <- plot_ocean_temps(clean_data = my_clean_df)
plot_ocean_temps <- function(clean_data) { 
  
  # load dependencies ----
  library(dplyr)
  library(ggplot2)
  library(ggridges)
  
  # get site name for plot title ----
  site_name <- unique(clean_data$site)
  
  # plot data ----
  temp_plot <- clean_data |> 
    group_by(month_name) |> 
    ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
    ggridges::geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
    scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
    scale_y_discrete(limits = rev(month.name)) + 
    scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
    labs(x = "Bottom Temperature (°C)",
         title = paste("Bottom Temperatures at",  site_name, ", Santa Barbara, CA"), # 2
         subtitle = "Temperatures (°C) aggregated by month from 2005 - 2022") +
    ggridges::theme_ridges(font_size = 13, grid = TRUE) +
    theme(
      axis.title.y = element_blank()
    )
  
  # return plot ----
  return(temp_plot)
}
```

:::

## **`r fontawesome::fa("rocket", fill = "#5A5A5A", a11y = "sem")` Stage 3:** Write for loops to read in, clean, and plot all your data

Our functions certainly get the job done, and we might decide to stop there. But you might imagine a situation where we actually have dozens, or even hundreds of files to process/plot -- writing a for loop to iterate over those data sets may save us time/effort/potential coding errors.

### **i.** Write a for loop to **read in** all raw data files

ADD NOTE ABOUT TESTING FOR LOOPS BY SETTING i = 1

::: panel-tabset

## Step 1:

1.  get list of files that you want to work with
2.  create the skeleton of a for loop to iterate over that list of files
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

# get list of temperature files ----
temp_files <- list.files(path = "data/raw_data", pattern = ".csv")

# for loop to read in each file ---
for (i in 1:length(temp_files)){
  
}
```

## Step 2: 

1.  create object name that your data will be saved to (`r fontawesome::fa("book-open-reader", fill = "#5A5A5A", a11y = "sem")` I learned how to do this by referencing the [`{stringr}` documentation](https://stringr.tidyverse.org/reference/str_split.html))
2.  add some helpful messages so you can more easily check progress
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

# get list of temperature files ----
temp_files <- list.files(path = "data/raw_data", pattern = ".csv")

# for loop to read in each file ---
for (i in 1:length(temp_files)){
  
  # get object name from file name ----
  file_name <- temp_files[i]
  message("Reading in: ", file_name)
  split_name <- stringr::str_split_1(file_name, "_")
  site_name <- split_name[1] 
  message("Saving as: ", site_name)
  
}
```

## Step 3:

1.  assign the read-in data to the object name (`r fontawesome::fa("book-open-reader", fill = "#5A5A5A", a11y = "sem")` I used [this resource](https://statisticsglobe.com/r-write-read-multiple-csv-files-for-loop) to remind myself how to do this)
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

# get list of temperature files ----
temp_files <- list.files(path = "data/raw_data", pattern = ".csv")

# for loop to read in each file ---
for (i in 1:length(temp_files)){
  
  # get object name from file name ----
  file_name <- temp_files[i]
  message("Reading in: ", file_name)
  split_name <- stringr::str_split_1(file_name, "_")
  site_name <- split_name[1] 
  message("Saving as: ", site_name)
  
  # read in csv and assign to our object name ----
  assign(site_name, readr::read_csv(here::here("data", "raw_data", file_name))) 
  
}
```

:::

### **ii.** Write a for loop to **clean** all data

::: panel-tabset

## Step 1: 

1.  create a vector of data frame names that you want to clean
2.  create skeleton of your for loop to iterate over that vector of names
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

# get list of dfs to clean ----
raw_data <- c("alegria", "carpinteria", "mohawk")

# for loop to clean dfs using `clean_ocean_temps()` ----
for (i in 1:length(raw_data)) {

}
```

## Step 2: 

1.  create object name to save the cleaned data frame to
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

# get list of dfs to clean ----
raw_data <- c("alegria", "carpinteria", "mohawk")

# for loop to clean dfs using `clean_ocean_temps()` ----
for (i in 1:length(raw_data)) {
  
  # get df ----
  message("cleaning df", i, ": -------- ", raw_data[i], " --------")
  get(raw_data[i])  # ! https://community.rstudio.com/t/loop-through-all-dfs-in-environment/70943 !
  
  # create new name ----
  df_name <- raw_data[i]
  df_clean_name <- paste0(df_name, "_clean")
  message("New df will be named: ", df_clean_name)

}
```

## Intermediate Step:

1. figure out how to call objects from the environment using variable names (`r fontawesome::fa("book-open-reader", fill = "#5A5A5A", a11y = "sem")` I referenced [this resource](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/get))
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

# get list of dfs to clean ----
raw_data <- c("alegria", "carpinteria", "mohawk")

# call an object from environment ----
test <- get(raw_data[1]) 
```

## Step 3: 

1.  assign the cleaned data frame to the object name, `df_clean_name` (just as we did when we read in data earlier)
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

# get list of dfs to clean ----
raw_data <- c("alegria", "carpinteria", "mohawk")

# for loop to clean dfs using `clean_ocean_temps()` ----
for (i in 1:length(raw_data)) {
  
  # print message ----
  message("cleaning df ", i, ": -------- ", raw_data[i], " --------")
  
  # create new df name ----
  df_name <- raw_data[i]
  df_clean_name <- paste0(df_name, "_clean")
  message("New df will be named: ", df_clean_name)
  
  # clean data ----
  assign(df_clean_name, clean_ocean_temps(df = get(raw_data[i]), include_temps = c("Temp_top", "Temp_bot")))
  
  message("------------------------------------")
}
```

:::

### **iii.** Write a for loop to **plot** all data


### **iv.** Putting it all together


Okay, now let's bring all these pieces together! Our revised scripts might look something like this:

::: panel-tabset
## `my_analysis.R`
```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false

```

## `R/clean_ocean_temps.R`
::: {.callout-note}
## Use a roxygen skeleton to document your function
Even if you don't plan to publish your function as part of a package, documenting your work is still a critical part of reproducibility and usability. This may be done in more informal ways, such as code annotations and text explanations in RMarkdown documents, for example. You may also consider more formal documentation -- the [`{roxygen2}`](https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html) package helps to make that process easier. Click anywhere inside your function, then choose Code > Insert Roxygen Skeleton to get started. 
:::

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
#' Process CDT/ADCP temperature data
#'
#' @param raw_data data frame of CTD/ADCP data collected at SBC LTER site moorings; search for data on the EDI Data Portal (http://portal.edirepository.org:80/nis/simpleSearch?defType=edismax&q=SBC+LTER%5C%3A+Ocean%5C%3A+Currents+and+Biogeochemistry%5C%3A+Moored+CTD+and+ADCP+data&fq=-scope:ecotrends&fq=-scope:lter-landsat*&fl=id,packageid,title,author,organization,pubdate,coordinates&debug=false)
#' @param include_temps vector of character strings that includes one or more of the following variable names: Temp_top, Temp_mid, Temp_top
#'
#' @return a data frame
#' @export
#'
#' @examples
#' my_clean_df <- clean_ocean_temps(raw_data = my_raw_df, include_temps = c("Temp_bot"))
clean_ocean_temps <- function(raw_data, include_temps = c("Temp_top", "Temp_mid", "Temp_bot")){ 
  
  # load dependencies ----
  library(dplyr) 
  library(tidyr)
  library(stringr) 
  library(chron)
  library(naniar)
  
  # if data contains these colnames, clean the script
  if(all(c("year", "month", "day", "decimal_time", "Temp_bot", "Temp_top", "Temp_mid") %in% colnames(raw_data))) { 
    
    message("Cleaning data...") 
    
    # get site name as character string from object (raw_data) name ----
    site_name <- deparse(substitute(raw_data)) 
    site_name <- paste(str_to_title(site_name), "Reef") 
    
    # columns to select ----
    standard_cols <- c("year", "month", "day", "decimal_time") 
    all_cols <- append(standard_cols, include_temps) 
    
    # clean data ----
    temps_clean <- raw_data |> 
      select(all_of(all_cols)) |> 
      filter(year %in% c(2005:2020)) |> 
      mutate(site = rep(site_name)) |> 
      unite(col = date, year, month, day, sep = "-", remove = FALSE) |> 
      mutate(time = times(decimal_time)) |> 
      unite(col = date_time, date, time, sep = " ", remove = TRUE) |> 
      mutate(date_time = as.POSIXct(date_time, "%Y-%m-%d %H:%M:%S", tz = "GMT"),
             year = as.factor(year),
             month = as.factor(month),
             day = as.numeric(day)) |>
      mutate(month_name = as.factor(month.name[month])) |>
      replace_with_na(replace = list(Temp_bot = 9999, Temp_top = 9999, Temp_mid = 9999)) |> 
      select(any_of(c(site, date_time, year, month, day, month_name, Temp_bot, Temp_mid, Temp_top))) 
    
    # return cleaned df ----
    return(temps_clean) 
    
  } else { 
    
    stop("The data frame provided does not include the necessary columns. Double check your data!") 
    
  }
  
}
```

## `R/plot_ocean_temps.R`

::: {.callout-note}
## Use a roxygen skeleton to document your function
Even if you don't plan to publish your function as part of a package, documenting your work is still a critical part of reproducibility and usability. This may be done in more informal ways, such as code annotations and text explanations in RMarkdown documents, for example. You may also consider more formal documentation -- the [`{roxygen2}`](https://cran.r-project.org/web/packages/roxygen2/vignettes/roxygen2.html) package helps to make that process easier. Click anywhere inside your function, then choose Code > Insert Roxygen Skeleton to get started. 
:::

```{r}
#| eval: false
#| echo: true
#| message: false
#| warning: false
#' Create ridge line plot of CDT/ADCP bottom temperature data
#'
#' @param clean_data a data frame that has been pre-processed using clean_ocean_temp()
#'
#' @return a plot object
#' @export
#'
#' @examples
#' my_plot <- plot_ocean_temps(clean_data = my_clean_df)
plot_ocean_temps <- function(clean_data) { 
  
  # load dependencies ----
  library(dplyr)
  library(ggplot2)
  library(ggridges)
  
  # get site name for plot title ----
  site_name <- unique(clean_data$site)
  
  # plot data ----
  temp_plot <- clean_data |> 
    group_by(month_name) |> 
    ggplot(aes(x = Temp_bot, y = month_name, fill = after_stat(x))) +
    ggridges::geom_density_ridges_gradient(rel_min_height = 0.01, scale = 3) + 
    scale_x_continuous(breaks = c(9, 12, 15, 18, 21)) +
    scale_y_discrete(limits = rev(month.name)) + 
    scale_fill_gradientn(colors = c("#2C5374","#778798", "#ADD8E6", "#EF8080", "#8B3A3A"), name = "Temp. (°C)") +
    labs(x = "Bottom Temperature (°C)",
         title = paste("Bottom Temperatures at",  site_name, ", Santa Barbara, CA"), # 2
         subtitle = "Temperatures (°C) aggregated by month from 2005 - 2022") +
    ggridges::theme_ridges(font_size = 13, grid = TRUE) +
    theme(
      axis.title.y = element_blank()
    )
  
  # return plot ----
  return(temp_plot)
}
```

:::


